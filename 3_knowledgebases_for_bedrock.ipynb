{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge bases for Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-agent-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_id = \"LABZ5ZLX8R\"\n",
    "model_arn = \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(question: str):\n",
    "\n",
    "    response = client.retrieve_and_generate(\n",
    "        input={\"text\": question},\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                \"knowledgeBaseId\": knowledge_base_id,\n",
    "                \"modelArn\": model_arn,\n",
    "                \"orchestrationConfiguration\": {\n",
    "                    \"queryTransformationConfiguration\": {\"type\": \"QUERY_DECOMPOSITION\"}\n",
    "                },\n",
    "                \"retrievalConfiguration\": {\n",
    "                    \"vectorSearchConfiguration\": {\"overrideSearchType\": \"HYBRID\"}\n",
    "                },\n",
    "            },\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"testdataset.json\")\n",
    "\n",
    "question = df[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_and_generate(question=question[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "citations = []\n",
    "\n",
    "for q in question:\n",
    "    response = retrieve_and_generate(question=q)\n",
    "\n",
    "    answers.append(response[\"output\"][\"text\"])\n",
    "    citations.append(response[\"citations\"])\n",
    "\n",
    "    print(q)\n",
    "    print(response[\"output\"][\"text\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kb_answers\"] = answers\n",
    "df[\"kb_citations\"] = citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"answer_data_kb_for_bedrock.json\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"answer_data_kb_for_bedrock.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = df[\"question\"]\n",
    "answer = df[\"kb_answers\"]\n",
    "ground_truth = df[\"ground_truth\"]\n",
    "context = []\n",
    "\n",
    "for citations in df[\"kb_citations\"]:\n",
    "    tmp = []\n",
    "    for citation in citations:\n",
    "        for retrievedReferences in citation[\"retrievedReferences\"]:\n",
    "            text = json.loads(retrievedReferences[\"content\"][\"text\"])\n",
    "            body = text[\"body\"]\n",
    "            tmp.append(body)\n",
    "    context.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "eval_data = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"contexts\": context,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "llm = AzureChatOpenAI(azure_deployment=os.getenv(\"AZURE_DEPLOYMENT_GPT4OMINI\", None))\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.getenv(\"AZURE_DEPLOYMENT_EMBEDDINGS\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    ")\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "run_config = RunConfig(max_wait=600, max_retries=100)\n",
    "\n",
    "result = evaluate(\n",
    "    eval_data,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=llm,\n",
    "    embeddings=embeddings,\n",
    "    run_config=run_config,\n",
    "    raise_exceptions=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = result.to_pandas()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_json(\"eval_data_kb_for_bedrock.json\", force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
